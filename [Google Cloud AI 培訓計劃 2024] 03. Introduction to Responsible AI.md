# Introduction to Responsible AI

這個入門微學習課程主要介紹「負責任的 AI 技術」和其重要性，
以及 Google 如何在自家產品中導入這項技術。本課程也會說明 Google 的 7 個 AI 開發原則。

### 「負責任的 AI 技術」簡介

![image](https://github.com/user-attachments/assets/70c3e788-3f07-4eaa-bee2-84187b21d218)

瞭解機構為何要實踐負責任的 AI 技術 瞭解機構為何要實踐負責任的 AI 技術 瞭解負責任的 AI 技術 
如何影響各專案階段中的所有決策 瞭解負責任的 AI


沒關係 這就是本課程存在的意義 我是 Google 的資安工程師 Manny 今天，我會帶您一起瞭解 Google 採用 AI 開發原則的理由 今天，我會帶您一起瞭解 Google 採用 AI 開發原則的理由 瞭解機構為何要實踐負責任的 AI 技術 瞭解機構為何要實踐負責任的 AI 技術 瞭解負責任的 AI 技術 如何影響各專案階段中的所有決策 瞭解負責任的 AI
00:34
技術 如何影響各專案階段中的所有決策 以及瞭解機構 如何依據本身的業務需求和價值觀 量身打造 AI 工具 聽起來很不錯 那就開始吧 您可能沒有意識到 大多數人在日常生活中 早已與人工智慧 (AI) 有過互動 像是查看路況和天氣 以及推薦您接下來 可能會想看的電視節目等 隨著 AI 日益普及 許多不支援 AI 的技術 開始顯得較為遜色 像是無法上網的電話 開始顯得較為遜色 像是無法上網的電話 現在的

![image](https://github.com/user-attachments/assets/98514751-c13b-406b-9bbf-f814ff0a41a1)
![image](https://github.com/user-attachments/assets/4a4d0488-15c2-4aa1-a1f3-8f6ef8b2270b)
![image](https://github.com/user-attachments/assets/0b50786c-c721-4ba4-8ad5-2dfac0c4da7f)

01:06
AI 系統能讓電腦 以十年前無法想像的方式 現在的 AI 系統能讓電腦 以十年前無法想像的方式 看見、理解世界，並與世界互動 這些系統正以驚人速度發展 但我們必須記得 儘管有許多突破性的進展 AI 並非完美無瑕 為了開發負責任的 AI 技術 我們必須瞭解 可能出現的問題、限制 或非預期的結果 科技會反映社會現況 如果沒有適當的做法 AI 可能會帶來相同的問題或偏見 甚至使情況加劇 這就是棘手之處 因為「負責任的 AI 技術」

![image](https://github.com/user-attachments/assets/823a90d7-30f2-4cce-b46e-3a323d641605)

01:49
其實並沒有通用定義 或簡潔明瞭的檢查清單 也沒有公式定義 該如何實踐負責任的 AI 技術 也沒有公式定義 該如何實踐負責任的 AI 技術 因此，許多機構會擬定 自家的 AI 開發原則 因此，許多機構會擬定 自家的 AI 開發原則 體現各自的使命和價值觀 雖然各機構制定的原則不盡相同 但幸運的是 這些原則在透明度 公平性、可靠度和隱私權方面 具有一致的理念 現在來看看 Google 的做法 我們對負責任

02:19

![image](https://github.com/user-attachments/assets/2d7cc825-51cf-4f89-b25a-116710cb81a9)
![image](https://github.com/user-attachments/assets/64fb48ee-cc2b-4732-81ae-f0d1a32c5c1d)


AI 技術的做法 源自於我們的承諾 也就是致力打造 人人都能使用的 AI 不僅要可靠安全 還要尊重隱私權 此外更要追求科學卓越 我們制定自己的 AI 開發原則 具體做法、管理程序和工具 我們制定自己的 AI 開發原則 具體做法、管理程序和工具 不僅體現 Google 的價值觀 同時也指引我們實踐負責任的 AI 技術 我們在設計產品時 就秉持著負責任的態度 我們在設計產品時 就秉持著負責任的態度 更重要的是
02:47

![image](https://github.com/user-attachments/assets/c4a27170-b34a-4e49-a1d3-3239d505cf8d)
 ![image](https://github.com/user-attachments/assets/4bb9c8fa-c82b-4d1a-a867-f6d4e2c66a7f)


Google 也秉持著同樣的理念 如同許多企業 我們以自家的 AI 開發原則為架構 引導出負責任的決策 每個人都會影響 AI 技術的採用情形 無論在 AI 開發程序的哪個階段 包括設計、部署或應用 所有人的決策都會造成影響 所以具備一套定義明確 並且可重複執行的程序 才會如此重要 這樣才能以負責任的方式使用 AI 談到人工智慧 大家常見的迷思 是以為決策時是機器在主導 事實上，設計和建構這些機器 並決定使用方式的人 才是真正的決策者 讓我解釋一下 AI


03:34

![image](https://github.com/user-attachments/assets/4ccf25e7-8b2a-4e61-b6c0-a9146af7ffc9)
![image](https://github.com/user-attachments/assets/3f98fab8-bcdb-43f5-841b-6e8a224d77cd)
![image](https://github.com/user-attachments/assets/c4b6e1de-19b1-48b3-9f05-75e29e5bc0ca)


開發的每個面向都有真人參與 他們會收集或建立資料來訓練模型 他們會收集或建立資料來訓練模型 然後控管 AI 部署作業 以及特定情境的應用方式 歸根究底 開發科技產品時 人類決策才是串起每個階段的關鍵 每當有人做出決定 其實就是根據自己價值觀做出選擇 無論是決定將生成式 AI 用於替代其他解決方案 無論是決定將生成式 AI 用於替代其他解決方案 或用在機器學習生命週期的任何階段 都是個人價值觀的體現 也就是說 每次下決策前 都需要仔細考量與評估 確保從概念發想 到部署和維護等階段 都以負責任的態度做出選擇 由於這些技術可能會對社會各層面 乃至於人們的日常生活造成影響


04:23

![image](https://github.com/user-attachments/assets/bd0a2723-d192-44f1-b347-ec008425d1d1)

因此開發這些技術時 務必顧及須遵守的倫理 負責任的 AI 技術 並非只著眼於明顯有爭議的用途 負責任的 AI 技術 並非只著眼於明顯有爭議的用途 如果沒有負責任的 AI 技術做法 就算是看似無害 或立意良好的 AI 用途 依舊可能產生倫理問題 或未預期的結果 還可能讓實際效益大打折扣 倫理和責任十分重要 不僅因為這是該做的事 也是因為能引導 AI 設計 為人類生活帶來更多益處 這與 Google 有何關係呢？


04:57
![image](https://github.com/user-attachments/assets/785e0721-4d46-4a7f-a885-a6235966bdf4)

我們深知在 AI 部署中 建立負責任的概念 有助於建構更好的模型 並能增進客戶 以及客戶的客戶對我們的信任 並能增進客戶 以及客戶的客戶對我們的信任 如果信任遭到破壞 AI 部署作業就有可能停滯或失敗 最糟的是 可能對這些產品的利害關係人造成危害 最糟的是 可能對這些產品的利害關係人造成危害

05:16

![image](https://github.com/user-attachments/assets/74bc1e97-015e-42d8-b7b0-edb3581f8d97)

這些都與 Google 的理念相關 這些都與 Google 的理念相關 也就是負責任的 AI 技術 才是成功的 AI 
我們打造 AI 相關產品及做出業務決策前 會經過一系列的評估與審查程序 這是為了確保我們在各產品領域和地理區域

05:32

都採用嚴謹且一致的方法 這是為了確保我們在各產品領域和地理區域 都採用嚴謹且一致的方法 這些評估與審查程序 首先會確保 任何專案均符合我們的 AI 開發原則 雖然 AI 開發原則 能讓團隊認可共同擔負的承諾 雖然 AI 開發原則 能讓團隊認可共同擔負的承諾

05:48
![image](https://github.com/user-attachments/assets/b8bbf3a2-f626-4440-a652-046c24c108c2)

但在如何負責任地設計產品上 並非所有人都會贊同每一個決策 這就是制定人們可信任的完善程序 如此重要的原因 這就是制定人們可信任的完善程序 如此重要的原因 即使他們不同意最終決策 依舊會信任做出決策的程序 我們剛才講了很多 指導原則在理論上對於 AI 的重要性 我們剛才講了很多 指導原則在理論上對於 AI 的重要性 那麼，在實踐中呢？

06:11

現在就來談談這個部分 
2018 年 6 月 我們公布了七項 AI 開發原則 做為實踐指導方針 這些具體標準 
可有效規範我們的研究和產品開發作業 這些具體標準 
並對業務決策造成影響 以下簡要說明這些原則 

第一，AI 應對社會有益

![image](https://github.com/user-attachments/assets/f60d3f59-8f21-48d7-8090-075497482f25)
![image](https://github.com/user-attachments/assets/0d3b62b5-8af2-4738-98f1-ed8272256df0)

06:30

無論任何專案 都必須考量多項社會和經濟因素 只有在我們認為整體可創造的利益 遠大於可預見的風險和缺點時 只有在我們認為整體可創造的利益 遠大於可預見的風險和缺點時 才會開始執行 
第二，AI 應避免塑造或加深不公平的偏誤 我們會努力避免對人們造成不公平的影響 尤其是當對象具有敏感特徵時 例如族裔、種族、性別、國籍 收入、性傾向、殘疾 以及政治立場或宗教信仰 

![image](https://github.com/user-attachments/assets/9d6011f7-93e7-4fec-8f72-00ce8d0c21eb)

第三，AI 應設有防護措施並通過安全測試 我們會繼續開發及採用高強度的安全措施

07:14
我們會繼續開發及採用高強度的安全措施 以防範可能會導致損害的意外結果 
![image](https://github.com/user-attachments/assets/760594c7-21bf-43a3-9093-c1a78dd66fec)

第四，AI 應對使用者負責 Google 設計的 AI 系統 會提供適當機會 讓人們提出意見、相關說明和訴求 會提供適當機會 讓人們提出意見、相關說明和訴求 

![image](https://github.com/user-attachments/assets/43117b7d-3e21-472e-8a33-90998be2a62b)
![image](https://github.com/user-attachments/assets/2b2facce-9555-4c85-a5ce-0e65b601db80)


第五，AI 應採用隱私設計原則 除了在使用流程中 提供發布聲明與徵求同意的機會 我們也鼓勵在系統架構中

07:38

設置隱私保護措施 以及適度公開資料使用情況 並提供相關控管選項 

![image](https://github.com/user-attachments/assets/72ef1905-c0bc-406b-8dd4-7875c4354518)
![image](https://github.com/user-attachments/assets/259b7126-1332-4b8a-9b2f-041a6d4875f2)

第六，AI 應堅持以高標準追求科學卓越 我們會與各相關單位合作 利用科學邏輯嚴謹的跨領域整合方法 利用科學邏輯嚴謹的跨領域整合方法 在 AI 領域推動審慎領導機制 此外，我們會妥善分享 AI 相關知識 發布各種教育資源、最佳做法和研究資料 發布各種教育資源、最佳做法和研究資料

08:04

協助更多人 開發實用的 AI 技術應用方式 

第七，AI 應以上述原則做為應用基準 科技往往有多種不同用途 我們會盡力限制 可能有害或不當的應用情境 我們會盡力限制 可能有害或不當的應用情境 以上就是我們的七項原則 但在這七項原則以外 有幾個我們不考慮發展的 AI
![image](https://github.com/user-attachments/assets/6c8d3454-ece2-4918-ba50-c32a005f5447)
![image](https://github.com/user-attachments/assets/5b8f3a09-53bb-4894-a6dd-514f457a2511)
![image](https://github.com/user-attachments/assets/7f6ea033-9758-4761-9e88-d0483bf4b8a3)
![image](https://github.com/user-attachments/assets/99443cae-9990-4165-80c9-a344a4f1eb0a)


技術應用領域 我們不會為以下四種應用領域 設計或部署 AI 技術 我們不會為以下四種應用領域 設計或部署 AI 技術 可能或確實會對整體造成危害的科技 武器或首要目的或用途為使人受傷 武器或首要目的或用途為使人受傷 或直接促成人身傷害的其他科技 為達監控目的 以違反國際公認規範的方式 收集或使用資訊的科技 以及與目前廣泛採納的國際法規 或人權原則相抵觸的技術

以及與目前廣泛採納的國際法規 或人權原則相抵觸的技術 制定這些開發原則只是開始 而不是終點 事實是，我們的 AI 開發原則 事實是，我們的 AI 開發原則 很少直接解答該如何打造產品 這些原則不會也不該 讓我們迴避艱難的對話 這些原則不會也不該 讓我們迴避艱難的對話 這些原則是 Google

的基礎 決定了 Google 的價值 要建構什麼產品 以及建構的理由 這些原則 是我們企業型 AI 產品成功的關鍵 這些原則 是我們企業型 AI 產品成功的關鍵 謝謝收看 如要進一步瞭解 AI 別忘了觀看其他影片

### 「負責任的 AI 技術」簡介：測驗


check
1.

為什麼負責任的 AI 技術做法對機構來說很重要？

負責任的 AI 技術做法有助於提高作業效率。
check
負責任的 AI 技術做法可讓客戶和利害關係人信任機構。

負責任的 AI 技術做法可以提高溝通效率。

負責任的 AI 技術做法有助於增加收益。
答對了！

check
2.

Google 有 7 項 AI 開發原則，下列何者為其中之一？

AI 應堅持以高標準追求營運成效。
check
AI 應堅持以高標準追求科學卓越。

AI 應塑造不公平的偏誤。

AI 應基於監控目的而收集或使用資訊。
答對了！

check
3.

關於實踐負責任的 AI 技術做法，下列何者正確？

專案後期的決策不會影響負責任的 AI 技術。

無論在專案的哪個階段，只有專案擁有者的決策才會影響負責任的 AI 技術。

專案初期的決策不會影響負責任的 AI 技術。
check
專案每個階段的決策都會影響負責任的 AI 技術。
答對了！

close
4.

機構紛紛擬定 AI 開發原則，體現自己的使命與價值。這些原則有哪些共通點？
close
均以公平、可靠和多元包容為理念。

均以資訊公開、公平和公正為理念。

均以資訊公開、公平、可靠和隱私權為理念。

均以資訊公開、公平和多樣性為理念。
答錯了。多元包容並非其中一項共通理念。








